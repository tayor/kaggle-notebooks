{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply Pseudo Labelling to best TPOT Model in the Instant Gratification Competition\n",
    "Code of this notebook is borrowed from  [Pseudo Labeling - QDA - [0.969]](https://www.kaggle.com/cdeotte/pseudo-labeling-qda-0-969). Thanks to Chris for his work. We search the best model for the first 'wheezy-copper-turtle-magic' chunck of train dataset then apply it to the whole problem. Only a small number of iterations is performed to demonstrate the workflow. \n",
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, pandas as pd, os\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from tpot import TPOTClassifier\n",
    "from tqdm import tqdm \n",
    "from warnings import simplefilter\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "\n",
    "\n",
    "simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "\n",
    "train = pd.read_csv('../input/train.csv')\n",
    "test = pd.read_csv('../input/test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Find the best TPOT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "238eae94140a4adab23c7872bec5ae81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Optimization Progress', max=1530, style=ProgressStyle(descrip…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 1 - Current best internal CV score: 0.8730429851119507\n",
      "Generation 2 - Current best internal CV score: 0.9112851654518321\n",
      "Generation 3 - Current best internal CV score: 0.9112851654518321\n",
      "Generation 4 - Current best internal CV score: 0.9112851654518321\n",
      "Generation 5 - Current best internal CV score: 0.9112851654518321\n",
      "Generation 6 - Current best internal CV score: 0.9112851654518321\n",
      "Generation 7 - Current best internal CV score: 0.9112851654518321\n",
      "Generation 8 - Current best internal CV score: 0.9112851654518321\n",
      "Generation 9 - Current best internal CV score: 0.9221626181396297\n",
      "Generation 10 - Current best internal CV score: 0.9221626181396297\n",
      "Generation 11 - Current best internal CV score: 0.9238439880681261\n",
      "Generation 12 - Current best internal CV score: 0.936236788966674\n",
      "Generation 13 - Current best internal CV score: 0.936236788966674\n",
      "Generation 14 - Current best internal CV score: 0.936236788966674\n",
      "Generation 15 - Current best internal CV score: 0.936236788966674\n",
      "Generation 16 - Current best internal CV score: 0.936236788966674\n",
      "Generation 17 - Current best internal CV score: 0.936236788966674\n",
      "Generation 18 - Current best internal CV score: 0.936236788966674\n",
      "Generation 19 - Current best internal CV score: 0.9377727530026382\n",
      "Generation 20 - Current best internal CV score: 0.9377727530026382\n",
      "Generation 21 - Current best internal CV score: 0.9377727530026382\n",
      "Generation 22 - Current best internal CV score: 0.9402976706137626\n",
      "Generation 23 - Current best internal CV score: 0.9402976706137626\n",
      "Generation 24 - Current best internal CV score: 0.9492070137185079\n",
      "Generation 25 - Current best internal CV score: 0.9492070137185079\n",
      "Generation 26 - Current best internal CV score: 0.9492070137185079\n",
      "Generation 27 - Current best internal CV score: 0.9492070137185079\n",
      "Generation 28 - Current best internal CV score: 0.9493450515002239\n",
      "Generation 29 - Current best internal CV score: 0.9538757326113648\n",
      "Generation 30 - Current best internal CV score: 0.9558006063753189\n",
      "Generation 31 - Current best internal CV score: 0.9558006063753189\n",
      "Generation 32 - Current best internal CV score: 0.9558006063753189\n",
      "Generation 33 - Current best internal CV score: 0.9558006063753189\n",
      "Generation 34 - Current best internal CV score: 0.9558006063753189\n",
      "Generation 35 - Current best internal CV score: 0.9558006063753189\n",
      "Generation 36 - Current best internal CV score: 0.9558006063753189\n",
      "Generation 37 - Current best internal CV score: 0.9558006063753189\n",
      "Generation 38 - Current best internal CV score: 0.9558006063753189\n",
      "Generation 39 - Current best internal CV score: 0.9558006063753189\n",
      "Generation 40 - Current best internal CV score: 0.9581491252468264\n",
      "Generation 41 - Current best internal CV score: 0.9581491252468264\n",
      "Generation 42 - Current best internal CV score: 0.9581491252468264\n",
      "Generation 43 - Current best internal CV score: 0.9581491252468264\n",
      "Generation 44 - Current best internal CV score: 0.9581491252468264\n",
      "Generation 45 - Current best internal CV score: 0.9581491252468264\n",
      "Generation 46 - Current best internal CV score: 0.9581491252468264\n",
      "Generation 47 - Current best internal CV score: 0.9581491252468264\n",
      "Generation 48 - Current best internal CV score: 0.9581491252468264\n",
      "Generation 49 - Current best internal CV score: 0.9581491252468264\n",
      "Generation 50 - Current best internal CV score: 0.9581491252468264\n",
      "\r\n",
      "Best pipeline: KNeighborsClassifier(Normalizer(PCA(FastICA(Normalizer(input_matrix, norm=l1), tol=0.8500000000000001), iterated_power=6, svd_solver=randomized), norm=l1), n_neighbors=10, p=2, weights=distance)\n",
      "CPU times: user 1min 33s, sys: 9.16 s, total: 1min 42s\n",
      "Wall time: 13min 12s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "cols = [c for c in train.columns if c not in ['id', 'target']]\n",
    "cols.remove('wheezy-copper-turtle-magic')\n",
    "oof = np.zeros(len(train))\n",
    "preds = np.zeros(len(test))\n",
    "\n",
    "# ONLY TRAIN WITH DATA WHERE WHEEZY EQUALS 0\n",
    "# Change i to choose another group of train data\n",
    "i=0\n",
    "train2 = train[train['wheezy-copper-turtle-magic']==i]\n",
    "test2 = test[test['wheezy-copper-turtle-magic']==i]\n",
    "idx1 = train2.index; idx2 = test2.index\n",
    "train2.reset_index(drop=True,inplace=True)\n",
    "\n",
    "# FEATURE SELECTION (USE APPROX 40 OF 255 FEATURES)\n",
    "sel = VarianceThreshold(threshold=1.5).fit(train2[cols])\n",
    "train3 = sel.transform(train2[cols])\n",
    "test3 = sel.transform(test2[cols])\n",
    "  \n",
    "#Change generations and population_size to find better pipelines\n",
    "# Visit http://epistasislab.github.io/tpot/api/ for the API documentation\n",
    "tpot = TPOTClassifier(generations=50, population_size=30, verbosity=2, scoring='roc_auc', cv=3, max_eval_time_mins=1, random_state=42, n_jobs=-1)\n",
    "tpot.fit(train3,  train2['target'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 - Fit the TPOT model and predict on test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [13:45<00:00,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TPOT scores CV = 0.95831\n",
      "CPU times: user 19min 45s, sys: 34min 44s, total: 54min 29s\n",
      "Wall time: 13min 45s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# INITIALIZE VARIABLES\n",
    "cols = [c for c in train.columns if c not in ['id', 'target']]\n",
    "cols.remove('wheezy-copper-turtle-magic')\n",
    "oof = np.zeros(len(train))\n",
    "preds = np.zeros(len(test))\n",
    "\n",
    "# BUILD 512 SEPARATE MODELS\n",
    "for i in tqdm(range(512)):\n",
    "    # ONLY TRAIN WITH DATA WHERE WHEEZY EQUALS I\n",
    "    train2 = train[train['wheezy-copper-turtle-magic']==i]\n",
    "    test2 = test[test['wheezy-copper-turtle-magic']==i]\n",
    "    idx1 = train2.index; idx2 = test2.index\n",
    "    train2.reset_index(drop=True,inplace=True)\n",
    "    \n",
    "    # FEATURE SELECTION (USE APPROX 40 OF 255 FEATURES)\n",
    "    sel = VarianceThreshold(threshold=1.5).fit(train2[cols])\n",
    "    train3 = sel.transform(train2[cols])\n",
    "    test3 = sel.transform(test2[cols])\n",
    "    \n",
    "    # STRATIFIED K-FOLD\n",
    "    skf = StratifiedKFold(n_splits=11, random_state=42, shuffle=True)\n",
    "    for train_index, test_index in skf.split(train3, train2['target']):\n",
    "        \n",
    "        # MODEL AND PREDICT WITH TPOT best fitted pipeline\n",
    "        tpot.fitted_pipeline_.fit(train3[train_index,:],train2.loc[train_index]['target'])\n",
    "        oof[idx1[test_index]] = tpot.fitted_pipeline_.predict_proba(train3[test_index,:])[:,1]\n",
    "        preds[idx2] += tpot.fitted_pipeline_.predict_proba(test3)[:,1] / skf.n_splits\n",
    "       \n",
    "        \n",
    "# PRINT CV AUC\n",
    "auc = roc_auc_score(train['target'],oof)\n",
    "print('TPOT scores CV =',round(auc,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 & 4 - Add pseudo label data and build QDA model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:58<00:00,  8.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QDA scores CV = 0.96567\n",
      "CPU times: user 1min 21s, sys: 2min 27s, total: 3min 49s\n",
      "Wall time: 58.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# INITIALIZE VARIABLES\n",
    "test['target'] = preds\n",
    "oof = np.zeros(len(train))\n",
    "preds = np.zeros(len(test))\n",
    "\n",
    "# BUILD 512 SEPARATE MODELS\n",
    "for k in tqdm(range(512)):\n",
    "    # ONLY TRAIN WITH DATA WHERE WHEEZY EQUALS I\n",
    "    train2 = train[train['wheezy-copper-turtle-magic']==k] \n",
    "    train2p = train2.copy(); idx1 = train2.index \n",
    "    test2 = test[test['wheezy-copper-turtle-magic']==k]\n",
    "    \n",
    "    # ADD PSEUDO LABELED DATA\n",
    "    test2p = test2[ (test2['target']<=0.01) | (test2['target']>=0.99) ].copy()\n",
    "    test2p.loc[ test2p['target']>=0.5, 'target' ] = 1\n",
    "    test2p.loc[ test2p['target']<0.5, 'target' ] = 0 \n",
    "    train2p = pd.concat([train2p,test2p],axis=0)\n",
    "    train2p.reset_index(drop=True,inplace=True)\n",
    "    \n",
    "    # FEATURE SELECTION (USE APPROX 40 OF 255 FEATURES)\n",
    "    sel = VarianceThreshold(threshold=1.5).fit(train2p[cols])     \n",
    "    train3p = sel.transform(train2p[cols])\n",
    "    train3 = sel.transform(train2[cols])\n",
    "    test3 = sel.transform(test2[cols])\n",
    "        \n",
    "    # STRATIFIED K FOLD\n",
    "    skf = StratifiedKFold(n_splits=11, random_state=42, shuffle=True)\n",
    "    for train_index, test_index in skf.split(train3p, train2p['target']):\n",
    "        test_index3 = test_index[ test_index<len(train3) ] # ignore pseudo in oof\n",
    "        \n",
    "        # MODEL AND PREDICT WITH QDA\n",
    "        clf = QuadraticDiscriminantAnalysis(reg_param=0.5)\n",
    "        clf.fit(train3p[train_index,:],train2p.loc[train_index]['target'])\n",
    "        oof[idx1[test_index3]] = clf.predict_proba(train3[test_index3,:])[:,1]\n",
    "        preds[test2.index] += clf.predict_proba(test3)[:,1] / skf.n_splits\n",
    "               \n",
    "# PRINT CV AUC\n",
    "auc = roc_auc_score(train['target'],oof)\n",
    "print('QDA scores CV =',round(auc,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submit Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sub = pd.read_csv('../input/sample_submission.csv')\n",
    "sub['target'] = preds\n",
    "sub.to_csv('submission.csv',index=False)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.hist(preds,bins=100)\n",
    "plt.title('Final Test.csv predictions')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
